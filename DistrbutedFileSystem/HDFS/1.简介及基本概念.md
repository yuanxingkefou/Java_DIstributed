**#HDFS简介及基本概念**

当需要存储的数据集的大小超过了一台独立的物理计算机的存储能力时，就需要对数据进行分区并存储到若干台计算机上去。
管理网络中跨多台计算机存储的文件系统统称为分布式文件系统（distributed fileSystem）。

分布式文件系统由于其跨计算机的特性，所以依赖于网络的传输，势必会比普通的本地文件系统更加复杂，比如：
如何使得文件系统能够容忍节点的故障并且保证不丢失数据，这就是一个很大的挑战。

HDFS（Hadoop Distributed File System）是hadoop生态系统的一个重要组成部分，是hadoop中的的存储组件，在整个Hadoop中的地位非同一般，是最基础的一部分
，因为它涉及到数据存储，MapReduce等计算模型都要依赖于存储在HDFS中的数据。HDFS是一个分布式文件系统，以流式数据访问模式存储超大文件，将数据分块存储到
一个商业硬件集群内的不同机器上。

**##HDFS数据块**

每个磁盘都有默认的数据块大小，这是文件系统进行数据读写的最小单位。

HDFS同样也有数据块的概念，默认一个块（block）的大小为128MB（HDFS的块这么大主要是为了最小化寻址开销），要在HDFS中存储的文件可以划分为多个分块，
每个分块可以成为一个独立的存储单元。与本地磁盘不同的是，HDFS中小于一个块大小的文件并不会占据整个HDFS数据块。

**对HDFS存储进行分块有很多好处：**

* 一个文件的大小可以大于网络中任意一个磁盘的容量，文件的块可以利用集群中的任意一个磁盘进行存储。

* 使用抽象的块，而不是整个文件作为存储单元，可以简化存储管理，使得文件的元数据可以单独管理。

* 冗余备份。数据块非常适合用于数据备份，进而可以提供数据容错能力和提高可用性。每个块可以有多个备份（默认为三个），分别保存到相互独立的机器上去，
这样就可以保证单点故障不会导致数据丢失。


**##namenode和datanode**

HDFS集群的节点分为两类：namenode和datanode，以管理节点-工作节点的模式运行，即一个namenode和多个datanode。

namenode作为管理节点，它负责整个文件系统的命名空间，并且维护着文件系统树和整棵树内所有的文件和目录，这些信息以两个文件的形式（命名空间镜像文件和编辑日志文件）永久存储在namenode 的本地磁盘上。除此之外，同时，namenode也记录每个文件中各个块所在的数据节点信息，但是不永久存储块的位置信息，因为块的信息可以在系统启动时重新构建。

datanode作为文件系统的工作节点，根据需要存储并检索数据块，定期向namenode发送他们所存储的块的列表。

**为了使得namenode更加可靠，hadoop提供了两种机制：**

* 一是备份那些组成文件系统元数据持久状态的文件，比如：将文件系统的信息写入本地磁盘的同时，也写入一个远程挂载的网络文件系统（NFS），这些写操作实时同步并且保证原子性。
* 二是运行一个辅助namenode，用以保存命名空间镜像的副本，在namenode发生故障时启用。（也可以使用热备份namenode代替辅助namenode）。

![namenode](https://github.com/yuanxingkefou/Java_DIstributed/blob/master/DistrbutedFileSystem/HDFS/images/HDFS.png)

**##块缓存**

数据通常情况下都保存在磁盘，但是对于访问频繁的文件，其对应的数据块可能被显式的缓存到datanode的内存中，以堆外缓存的方式存在，一些计算任务（比如mapreduce）可以在缓存了数据的datanode上运行，利用块的缓存优势提高读操作的性能。

**##联邦HDFS**

namenode在内存中保存了文件系统中每个文件和每个数据块的引用关系，这意味着，当文件足够多时，namenode的内存将成为限制系统横向扩展的瓶颈。hadoop2.0引入了联邦HDFS允许系统通过添加namenode的方式实现扩展，每个namenode管理文件系统命名空间中的一部分，比如：一个namenode管理/usr下的文件，另外一个namenode管理/share目录下的文件。

**##HDFS的高可用性**

通过备份namenode存储的文件信息或者运行辅助namenode可以防止数据丢失，但是依旧没有保证了系统的高可用性。一旦namenode发生了单点失效，
那么必须能够快速的启动一个拥有文件系统信息副本的新namenode，

而这个过程需要以下几步：

（1）将命名空间的副本映像导入内存 

（2）重新编辑日志 

（3）接收足够多来自datanode的数据块报告，从而重建起数据块与位置的对应关系。

上述实际上就是一个namenode的冷启动过程，但是在数据量足够大的情况下，这个冷启动可能需要30分钟以上的时间，这是无法忍受的。

Hadoop2.0开始，增加了对高可用性的支持。采用了双机热备份的方式。同时使用一对活动-备用namenode，当活动namenode失效后，备用namenode可以迅速接管它的任务，这中间不会有任何的中断，以至于使得用户根本无法察觉。
为了实现这种双机热备份，HDFS架构需要作出以下几个改变：

* 两个namenode之间要通过高可用共享存储来实现编辑日志的共享

* datanode要同时向两个namenode发送数据块的报告信息

* 客户端要使用特定机制来处理namenode的失效问题

* 备用namenode要为活动namenode设置周期性的检查点，从中判断活动namenode是否失效

HDFS系统中运行着一个故障转移控制器，管理着将活动namenode转移为备用namenode的转换过程。同时，每一个namenode也运行着一个轻量级的故障转移控制器，

主要目的就是监视宿主namenode是否失效，并在失效时实现迅速切换。

